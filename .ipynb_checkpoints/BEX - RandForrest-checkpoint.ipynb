{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2acba3bc-0941-4ccc-b15a-503d3bdc3814",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Finished Importing\n"
     ]
    }
   ],
   "source": [
    "# Import necessary libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier # Changed: Import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "import os\n",
    "import cv2 # OpenCV for image loading and processing\n",
    "\n",
    "print (\"Finished Importing\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "605518c9-9209-43ec-bb60-916cf521b7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading images from: C:\\Users\\Bex\\OneDrive\\Documents\\GitHub\\asl_dataset\\asl_dataset\n",
      "Processing label: a\n",
      "Processing label: b\n",
      "Processing label: c\n",
      "Processing label: d\n",
      "Processing label: e\n",
      "Processing label: f\n",
      "Processing label: g\n",
      "Processing label: h\n",
      "Processing label: i\n",
      "Processing label: j\n",
      "Processing label: k\n",
      "Processing label: l\n",
      "Processing label: m\n",
      "Processing label: n\n",
      "Processing label: o\n",
      "Processing label: p\n",
      "Processing label: q\n",
      "Processing label: r\n",
      "Processing label: s\n",
      "Processing label: t\n",
      "Processing label: u\n",
      "Processing label: v\n",
      "Processing label: w\n",
      "Processing label: x\n",
      "Processing label: y\n",
      "Processing label: z\n",
      "Finished loading images. Total images loaded: 1815\n",
      "\n",
      "--- Sample of the loaded dataset (first 5 rows, first 10 pixels) ---\n",
      "   pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  pixel_8  \\\n",
      "0      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "1      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "2      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "3      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "4      0.0      0.0      0.0      0.0      0.0      0.0      0.0      0.0   \n",
      "\n",
      "   pixel_9  pixel_10  \n",
      "0      0.0       0.0  \n",
      "1      0.0       0.0  \n",
      "2      0.0       0.0  \n",
      "3      0.0       0.0  \n",
      "4      0.0       0.0  \n",
      "\n",
      "Total samples loaded: 1815\n",
      "Image dimensions used: 100x100 pixels\n",
      "Number of features (pixels): 10000\n",
      "Unique labels found: 26 (['a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i' 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r'\n",
      " 's' 't' 'u' 'v' 'w' 'x' 'y' 'z'])\n",
      "\n",
      "--- Data Characteristics Before Training ---\n",
      "Value counts for each label:\n",
      "label\n",
      "a    70\n",
      "b    70\n",
      "y    70\n",
      "x    70\n",
      "w    70\n",
      "v    70\n",
      "u    70\n",
      "s    70\n",
      "r    70\n",
      "q    70\n",
      "p    70\n",
      "o    70\n",
      "n    70\n",
      "m    70\n",
      "l    70\n",
      "k    70\n",
      "j    70\n",
      "i    70\n",
      "h    70\n",
      "g    70\n",
      "f    70\n",
      "e    70\n",
      "d    70\n",
      "c    70\n",
      "z    70\n",
      "t    65\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Statistical summary of features (first 10 pixels):\n",
      "           pixel_1      pixel_2      pixel_3      pixel_4      pixel_5  \\\n",
      "count  1815.000000  1815.000000  1815.000000  1815.000000  1815.000000   \n",
      "mean      0.000171     0.000192     0.003911     0.007981     0.011112   \n",
      "std       0.001770     0.001937     0.039810     0.067721     0.080340   \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000   \n",
      "max       0.027451     0.031373     0.658824     0.701961     0.780392   \n",
      "\n",
      "           pixel_6      pixel_7      pixel_8      pixel_9     pixel_10  \n",
      "count  1815.000000  1815.000000  1815.000000  1815.000000  1815.000000  \n",
      "mean      0.012763     0.008733     0.004689     0.002748     0.001424  \n",
      "std       0.088810     0.070414     0.050413     0.038303     0.027173  \n",
      "min       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "25%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "50%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "75%       0.000000     0.000000     0.000000     0.000000     0.000000  \n",
      "max       0.854902     0.854902     0.823529     0.721569     0.674510  \n",
      "\n",
      "Training set size: 1452 samples\n",
      "Testing set size: 363 samples\n",
      "\n",
      "--- Training the Random Forest model ---\n",
      "Model training complete.\n",
      "\n",
      "--- Model Evaluation ---\n",
      "Accuracy: 0.9752\n",
      "\n",
      "Classification Report:\n",
      "               precision    recall  f1-score   support\n",
      "\n",
      "           a       1.00      1.00      1.00        14\n",
      "           b       0.93      1.00      0.97        14\n",
      "           c       1.00      1.00      1.00        14\n",
      "           d       1.00      1.00      1.00        14\n",
      "           e       1.00      1.00      1.00        14\n",
      "           f       1.00      1.00      1.00        14\n",
      "           g       1.00      0.93      0.96        14\n",
      "           h       1.00      1.00      1.00        14\n",
      "           i       1.00      1.00      1.00        14\n",
      "           j       0.93      1.00      0.97        14\n",
      "           k       1.00      0.93      0.96        14\n",
      "           l       1.00      1.00      1.00        14\n",
      "           m       0.93      0.93      0.93        14\n",
      "           n       0.93      1.00      0.97        14\n",
      "           o       1.00      0.93      0.96        14\n",
      "           p       1.00      1.00      1.00        14\n",
      "           q       1.00      1.00      1.00        14\n",
      "           r       0.88      1.00      0.93        14\n",
      "           s       1.00      0.93      0.96        14\n",
      "           t       1.00      1.00      1.00        13\n",
      "           u       0.86      0.86      0.86        14\n",
      "           v       1.00      1.00      1.00        14\n",
      "           w       0.93      1.00      0.97        14\n",
      "           x       1.00      1.00      1.00        14\n",
      "           y       1.00      1.00      1.00        14\n",
      "           z       1.00      0.86      0.92        14\n",
      "\n",
      "    accuracy                           0.98       363\n",
      "   macro avg       0.98      0.98      0.98       363\n",
      "weighted avg       0.98      0.98      0.98       363\n",
      "\n",
      "\n",
      "--- Example Prediction for a Single New Image ---\n",
      "True ASL letter for sample: o\n",
      "Predicted ASL letter: o\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bex\\anaconda3\\Lib\\site-packages\\sklearn\\base.py:493: UserWarning: X does not have valid feature names, but RandomForestClassifier was fitted with feature names\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# --- Configuration for your dataset ---\n",
    "# Path to dataset: structured as \"dataset/A/A1.jpg\", \"dataset/B/B2.jpg\", etc.\n",
    "# IMPORTANT: REPLACE THIS WITH YOUR ACTUAL DATASET PATH\n",
    "DATASET_PATH = r\"C:\\Users\\Bex\\OneDrive\\Documents\\GitHub\\asl_dataset\\asl_dataset\"\n",
    "IMAGE_SIZE = (100, 100) # Images will be resized to 100x100 pixels\n",
    "\n",
    "# --- Your provided image loading function ---\n",
    "def load_images_and_labels(dataset_path):\n",
    "    \"\"\"\n",
    "    Loads images from the specified dataset path, resizes them,\n",
    "    converts them to grayscale, and collects their corresponding labels.\n",
    "\n",
    "    Args:\n",
    "        dataset_path (str): The root directory of the dataset,\n",
    "                            expected to contain subdirectories named after labels.\n",
    "\n",
    "    Returns:\n",
    "        tuple: A tuple containing:\n",
    "            - np.array: A NumPy array of image data (flattened pixels).\n",
    "            - np.array: A NumPy array of corresponding labels.\n",
    "    \"\"\"\n",
    "    X = [] # To store image data (flattened pixel arrays)\n",
    "    y = [] # To store labels\n",
    "\n",
    "    print(f\"Loading images from: {dataset_path}\")\n",
    "\n",
    "    # Iterate through each subdirectory (which represents a label/class)\n",
    "    for label in sorted(os.listdir(dataset_path)):\n",
    "        label_path = os.path.join(dataset_path, label)\n",
    "\n",
    "        # Skip if it's not a directory\n",
    "        if not os.path.isdir(label_path):\n",
    "            continue\n",
    "\n",
    "        print(f\"Processing label: {label}\")\n",
    "\n",
    "        # Iterate through each image file in the current label directory\n",
    "        for img_name in os.listdir(label_path):\n",
    "            img_path = os.path.join(label_path, img_name)\n",
    "\n",
    "            # Read the image in grayscale\n",
    "            img = cv2.imread(img_path, cv2.IMREAD_GRAYSCALE)\n",
    "\n",
    "            # Check if image was loaded successfully\n",
    "            if img is None:\n",
    "                print(f\"Warning: Could not load image {img_path}. Skipping.\")\n",
    "                continue\n",
    "\n",
    "            # Resize the image to the predefined IMAGE_SIZE\n",
    "            img = cv2.resize(img, IMAGE_SIZE)\n",
    "\n",
    "            # Flatten the 2D image array into a 1D feature vector\n",
    "            # Normalize pixel values to 0-1 range for better model performance\n",
    "            X.append(img.flatten() / 255.0)\n",
    "            y.append(label)\n",
    "\n",
    "    print(f\"Finished loading images. Total images loaded: {len(X)}\")\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# --- 1. Load Your ASL Handshape Image Data ---\n",
    "\n",
    "# Call your provided function to load the data\n",
    "X_raw, y_raw = load_images_and_labels(DATASET_PATH)\n",
    "\n",
    "# Check if any data was loaded\n",
    "if len(X_raw) == 0:\n",
    "    print(\"\\nERROR: No images were loaded. Please check your DATASET_PATH and ensure\")\n",
    "    print(\"       your dataset structure is correct (e.g., 'dataset_root/A/img.jpg').\")\n",
    "    print(\"       Exiting script as no data is available for training.\")\n",
    "    exit() # Exit the script if no data is loaded\n",
    "\n",
    "# Create a Pandas DataFrame from the loaded data\n",
    "# Each column represents a pixel (feature)\n",
    "num_features = IMAGE_SIZE[0] * IMAGE_SIZE[1]\n",
    "df = pd.DataFrame(X_raw, columns=[f'pixel_{i+1}' for i in range(num_features)])\n",
    "df['label'] = y_raw\n",
    "\n",
    "print(\"\\n--- Sample of the loaded dataset (first 5 rows, first 10 pixels) ---\")\n",
    "print(df.head().iloc[:, :10]) # Print only first 10 pixel columns for brevity\n",
    "print(f\"\\nTotal samples loaded: {len(df)}\")\n",
    "print(f\"Image dimensions used: {IMAGE_SIZE[0]}x{IMAGE_SIZE[1]} pixels\")\n",
    "print(f\"Number of features (pixels): {num_features}\")\n",
    "print(f\"Unique labels found: {df['label'].nunique()} ({df['label'].unique()})\")\n",
    "\n",
    "# --- Data Characteristics Before Training ---\n",
    "print(\"\\n--- Data Characteristics Before Training ---\")\n",
    "print(\"Value counts for each label:\")\n",
    "print(df['label'].value_counts())\n",
    "\n",
    "print(\"\\nStatistical summary of features (first 10 pixels):\")\n",
    "# Ensure X is defined before calling describe on it\n",
    "X_temp_for_describe = df.drop('label', axis=1)\n",
    "print(X_temp_for_describe.iloc[:, :10].describe())\n",
    "\n",
    "\n",
    "# --- 2. Preprocessing the Data ---\n",
    "\n",
    "# Separate features (X) and target (y)\n",
    "X = df.drop('label', axis=1)\n",
    "y = df['label']\n",
    "\n",
    "# Encode the categorical labels into numerical format\n",
    "# Random Forest works with numerical targets.\n",
    "label_encoder = LabelEncoder()\n",
    "y_encoded = label_encoder.fit_transform(y)\n",
    "\n",
    "# Split the data into training and testing sets\n",
    "# We'll use 80% for training and 20% for testing.\n",
    "# stratify=y_encoded ensures that the proportion of labels is the same in train and test sets.\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y_encoded, test_size=0.2, random_state=42, stratify=y_encoded)\n",
    "\n",
    "print(f\"\\nTraining set size: {len(X_train)} samples\")\n",
    "print(f\"Testing set size: {len(X_test)} samples\")\n",
    "\n",
    "# --- 3. Train the Random Forest Model ---\n",
    "\n",
    "# Initialize the Random Forest Classifier model\n",
    "# n_estimators: The number of trees in the forest. More trees generally lead to better performance\n",
    "#               but also increase computation time. 100 is a good starting point.\n",
    "# n_jobs=-1: Uses all available CPU cores for parallel processing, speeding up training.\n",
    "model = RandomForestClassifier(n_estimators=100, random_state=42, n_jobs=-1)\n",
    "\n",
    "# Train the model using the training data\n",
    "print(\"\\n--- Training the Random Forest model ---\")\n",
    "try:\n",
    "    model.fit(X_train, y_train)\n",
    "    print(\"Model training complete.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred during model training: {e}\")\n",
    "    print(\"This might indicate issues with data, memory, or model parameters.\")\n",
    "\n",
    "\n",
    "# --- 4. Make Predictions and Evaluate the Model ---\n",
    "\n",
    "# Only proceed with prediction and evaluation if the model trained successfully\n",
    "if hasattr(model, 'feature_importances_'): # Check if model has feature_importances_, indicating it trained\n",
    "    # Make predictions on the test set\n",
    "    y_pred_encoded = model.predict(X_test)\n",
    "\n",
    "    # Decode the numerical predictions back to original labels for better understanding\n",
    "    y_pred = label_encoder.inverse_transform(y_pred_encoded)\n",
    "    y_test_original = label_encoder.inverse_transform(y_test)\n",
    "\n",
    "    # Evaluate the model's performance\n",
    "    accuracy = accuracy_score(y_test_original, y_pred)\n",
    "    report = classification_report(y_test_original, y_pred, target_names=label_encoder.classes_)\n",
    "\n",
    "    print(f\"\\n--- Model Evaluation ---\")\n",
    "    print(f\"Accuracy: {accuracy:.4f}\")\n",
    "    print(\"\\nClassification Report:\\n\", report)\n",
    "\n",
    "    # --- Example of making a prediction on a new, unseen image ---\n",
    "    print(\"\\n--- Example Prediction for a Single New Image ---\")\n",
    "\n",
    "    # To make a prediction on a new image:\n",
    "    # 1. Load the new image using cv2.imread(new_img_path, cv2.IMREAD_GRAYSCALE)\n",
    "    # 2. Resize it: cv2.resize(img, IMAGE_SIZE)\n",
    "    # 3. Flatten it and normalize: img.flatten() / 255.0\n",
    "    # 4. Reshape it for prediction: new_image_features.reshape(1, -1)\n",
    "\n",
    "    # For demonstration, let's pick a random image from the test set and \"re-process\" it\n",
    "    # as if it were a new, unseen image to show the prediction flow.\n",
    "    if len(X_test) > 0:\n",
    "        random_idx = np.random.randint(0, len(X_test))\n",
    "        sample_image_features = X_test.iloc[random_idx].values.reshape(1, -1)\n",
    "        true_label = y_test_original[random_idx]\n",
    "\n",
    "        predicted_label_encoded = model.predict(sample_image_features)\n",
    "        predicted_letter = label_encoder.inverse_transform(predicted_label_encoded)\n",
    "\n",
    "        print(f\"True ASL letter for sample: {true_label}\")\n",
    "        print(f\"Predicted ASL letter: {predicted_letter[0]}\")\n",
    "    else:\n",
    "        print(\"Not enough data in the test set to demonstrate a new prediction example.\")\n",
    "else:\n",
    "    print(\"\\nModel did not train successfully, skipping prediction and evaluation.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc3d5883-cf4e-440c-9a17-956321eac925",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
